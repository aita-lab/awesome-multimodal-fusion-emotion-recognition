# <p align=center>`Multi-Modal Fusion in Speech Emotion Recognition: A Comprehensive Review of Methods and Technologies`</p> #

#### Citation
```python
# Update soon
```
#### Update
- **First release:** December 3rd, 2024. 

## Contents
- [Related Survey](#related-survey)
- [Data sets](#datasets)
- [Review of fusion methods in SER](#review-of-fusion-methods-in-ser)
    - [Early fusion](#early-fusion)
    - [Late fusion](#late-fusion)
    - [Deep-fusion](#deep-fusion)
    - [Hybrid-fusion](#hybrid-fusion)
- [Review of fusion technologies in SER](#review-of-fusion-technologies-in-SER)
    - [Data representation](#data-representation)
    - [Data translation](#data-translation)
    - [Attention mechanism](#attention-mechanism)
        - [Multi-head attention](#multi-head-attention)
        - [Cross-modality attention](#cross-modality-attention)
        - [Dual-attention network](#dual-attention-network)
        - [Graph attention network](#graph-attention-network)
    - [Graph-based fusion](#graph-based-fusion)


## Related Survey
**A snapshot research and implementation of multimodal information fusion for data-driven emotion recognition.**\
*Jiang, Y., Li, W., Hossain, M. S., Chen, M., Alelaiwi, A., & Al-Hammadi, M.*\
[2020] [Information Fusion]\
[[Paper](https://doi.org/10.1016/j.inffus.2019.06.019)]

**Survey on bimodal speech emotion recognition from acoustic and linguistic information fusion.**
*Atmaja, Bagus Tris, Akira Sasou, and Masato Akagi.*
[2022] [Speech Communication]
## Data sets

## Review of fusion methods in SER

### Early fusion

### Late fusion
### Deep fusion
### Hybrid fusion

## Review of fusion technologies in SER
### Data representation
### Data translation
### Attention mechanism
#### Multi-head attention
#### Cross-modality attention
#### Dual-attention network
#### Graph attention network
### Graph-based fusion
